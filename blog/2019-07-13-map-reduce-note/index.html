<!doctype html><html lang=zh-cn><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-143445286-1"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-143445286-1');</script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.55.6"><link rel="shorcut icon" href=https://baishen.me/><title>baishen | blog | Map Reduce笔记</title><link rel=stylesheet href=https://baishen.me/css/style.css><link rel=stylesheet href=https://baishen.me/css/syntax.css></head><body class="has-navbar-fixed-top page"><nav class="navbar is-fixed-top is-black"><div class=container><div class=navbar-brand><a class=navbar-item href=https://baishen.me/>baishen</a><div role=button class=navbar-burger aria-label=menu aria-expanded=false><span aria-hidden=true></span><span aria-hidden=true></span><span aria-hidden=true></span></div></div><div class=navbar-menu><div class=navbar-start><div class=navbar-item></div></div><div class=navbar-end><div class="navbar-item has-dropdown is-hoverable"><a class=navbar-link href=https://baishen.me/rust-note/>Rust Note</a><div class="navbar-dropdown is-hidden-touch"><a class=navbar-item href=https://baishen.me/rust-note/><strong>1</strong>. Introduction</a></div></div><div class=navbar-item><div class="field is-grouped"><p class=control><a class="button is-twitter-blue" target=_blank href=https://twitter.com/b41sh><span class="icon has-text-white"><i class="fab fa-twitter"></i></span><span>Twitter</span></a>
<a class="button is-inverted" target=_blank href=https://github.com/b41sh><span class=icon><i class="fab fa-github"></i></span><span>Github</span></a></p></div></div></div></div></div></nav><main class=main><section class="hero is-light"><div class=hero-body><div class=container><h1 class="title is-size-1 is-size-2-mobile has-text-black has-text-black-light">Map Reduce笔记</h1><p class="is-size-5 has-text-black-ter">2019-07-13</p><br></div></div></section><section class="section has-background-white"><div class=container><div class="content is-medium is-blog-content"><h2 id=1-介绍-introduction>1 介绍(Introduction)</h2><p>处理原始数据</p><ul><li>文档抓取</li><li>Web 请求日志</li></ul><p>处理衍生数据</p><ul><li>倒排索引</li><li>Web 文档的图结构(graph structure) 表示</li><li>每台主机爬虫抓取数量汇总</li><li>每天被请求最多的的查询的集合</li></ul><p>难点</p><ul><li>并行计算</li><li>分发数据</li><li>处理错误</li></ul><p>大多数运算包含相同的操作</p><ol><li>输入数据应用 Map 得到一个 key/value pair 集合</li><li>在相同 key 值的 value 上应用 Reduce 操作，合并数据，得到结果</li></ol><p>MapReduce 框架模型</p><ul><li>处理并行计算、容错、数据分布、负载均衡</li><li>通过简单的接口来实现自动的并行化和大规模的分布式计算</li></ul><h2 id=2-编程模型-programming-model>2 编程模型(Programming Model)</h2><p>利用一个输入 key/value pair 集合来产生一个输出的 key/value pair 集合</p><ul><li>用户自定义的 Map 函数接收 key/value pair，输出 key/value pair 集合</li><li>MapReduce 库把所有相同 key 的 value 集合后传递给 Reduce 函数</li><li>用户自定义的 Reduce 函数合并 value 值，形成较小的 value 值集合</li></ul><h3 id=2-1-例子-example>2.1 例子(Example)</h3><p>计算一个大的文档集合中每个单词出现的次数</p><pre><code>map(String key, String value):
    // key: document name
    // value: document contents for each word w in value:
    for each word w in value:
        EmitIntermediate(w, &quot;1&quot;);

reduce(String key, Iterator values):
    // key: a word
    // values: a list of counts
    int result = 0;
    for each v in values:
        result += ParseInt(v);
    Emit(AsString(result));
</code></pre><h3 id=2-2-类型-types>2.2 类型(Types)</h3><p>Map 和 Reduce 函数的类型是相关联的</p><pre><code>map    (k1,v1)       -&gt; list(k2,v2)
reduce (k2,list(v2)) -&gt; list(v2)
</code></pre><h3 id=2-3-更多的例子-more-examples>2.3 更多的例子(More Examples)</h3><h5 id=分布式-grep-distributed-grep>分布式 Grep(Distributed Grep)</h5><ul><li>Map 输出匹配某个模式的一行</li><li>Reduce 把中间数据复制到输出（恒等函数）</li></ul><h5 id=计算-url-访问频率-count-of-url-access-frequency>计算 URL 访问频率(Count of URL Access Frequency)</h5><ul><li>Map 处理日志中 web 页面请求的记录，输出(URL, 1)</li><li>Reduce 把相同 URL 的 value 值累加起来，产生(URL, total count)</li></ul><h5 id=反转-web-link-图-reverse-web-link-graph>反转 Web-Link 图(Reverse Web-Link Graph)</h5><ul><li>Map 在 source 中搜索所有的 target，输出 (target,source)</li><li>Reduce 把给定(target)的链接组合成一个列表，输出 (target,list(source))</li></ul><h5 id=每个-host-的检索词向量-term-vector-per-host>每个 Host 的检索词向量 (Term-Vector per Host)</h5><ul><li>Map 为每一个输入文档输出(hostname, term vector)，host来自文档的 URL</li><li>Reduce 按 word 累加 term vector，丢弃低频 term vector</li></ul><h5 id=倒排索引-inverted-index>倒排索引(Inverted Index)</h5><ul><li>Map 分析每个文档，输出一个 (word, document ID) 列表</li><li>Reduce 排序 document ID，输出 (word, document ID)</li></ul><h5 id=分布式排序-distributed-sort>分布式排序(Distributed Sort)</h5><ul><li>Map 从每个记录提取 key，输出 (key,record)</li><li>Reduce 函数不改变任何的值。这个运算依赖分区机制(4.1)和排序属性(4.2)</li></ul><h2 id=3-实现-implementation>3 实现(Implementation)</h2><p>Google 内部广泛使用的运行环境</p><ol><li>X86、Linux、双 CPU、2-4G 内存</li><li>百兆或千兆带宽</li><li>上千台机器，故障是常态</li><li>IDE 硬盘，GFS管理数据</li><li>用户提交 job 给调度系统，每个 job 包含一系列 task，调度系统将 task 调度到集群中多台可用的机器</li></ol><h3 id=3-1-执行概况-execution-overview>3.1 执行概况(Execution Overview)</h3><p>MapReduce 执行流程</p><ol><li>将文件分为 M 个数据片段，每个 16MB - 64MB(可配置)，在集群中创建大量副本</li><li>master 分配 map task 或 reduce task 给一个空闲的 worker</li><li>map worker 读取输入数据，解析出 key/value pair，传递给用户的 Map 函数，输出中间 key/value pair，存储在内存中</li><li>key/value pair 通过分区函数分为 R 个区域，周期性的写入到本地磁盘，把位置回传给 master</li><li>reduce worker 通过 RPC 读取数据，通过对 key 排序，使相同的 key 聚合到一起（数据太大需要外部排序）</li><li>reduce worker 遍历排序后的数据，将每一个 key 和相关的 value 集合传递给用户的 Reduce 函数，输出追加到所属分区的输出文件</li><li>所有 Map 和 Reduce task 完成后，调用返回</li></ol><h3 id=3-2-master-数据结构-master-data-structures>3.2 Master 数据结构(Master Data Structures)</h3><ul><li>Map 和 Reduce task 的状态（空闲、工作中、完成）</li><li>worker 机器的标识</li><li>Map task 产生的 R 个中间文件存储区域的大小和位置</li></ul><h3 id=3-3-容错-fault-tolerance>3.3 容错(Fault Tolerance)</h3><h5 id=worker-故障-worker-failure>Worker 故障(Worker Failure)</h5><ul><li>master 周期性的 ping 每个 worker，约定时间内没返回标记为失效，task 标记为空闲，等待重新调度</li><li>map task 的输出存储在本地，需要重新执行，reduce task 存储在 GFS，不需要重新执行</li><li>map task 重新执行会通知所有 reduce worker，重新读取数据</li><li>可以处理大规模 worker 失效的情况</li></ul><h5 id=master-故障-master-failure>Master 故障(Master Failure)</h5><ul><li>周期性的将数据写入磁盘，记录 checkpoint，新进程通过 checkpoint 继续执行</li><li>只有一个 master 进程，恢复麻烦，master 失效直接中止 MapReduce</li></ul><h5 id=在失效方面的处理机制-semantics-in-the-presence-of-failures>在失效方面的处理机制(Semantics in the Presence of Failures)</h5><ul><li>Map 和 Reduce 都是确定性函数时，在任何情况下的输出都和没有出现错误、顺序执行产生的输出相同</li><li>Map 和 Reduce task 的输出是原子提交</li></ul><h3 id=3-4-存储位置-locality>3.4 存储位置(Locality)</h3><p>尽量将 task 调度到包含输入数据(GFS)的机器上执行，节约网络带宽</p><h3 id=3-5-任务粒度-task-granularity>3.5 任务粒度(Task Granularity)</h3><ul><li>Map 拆分为 M 个片段，Reduce 拆分为 R 个片段</li><li>master 执行 O(M+R) 次调度，内存中保存 O(M*R)个状态</li><li>R 由用户指定，选择合适的 M，使每个独立 task 处理 16-64MB 数据</li><li>R 值设置为想使用的机器数量的小倍数</li><li>通常的 MapReduce 比例：M=200000，R=5000，2000台机器</li></ul><h3 id=3-6-备用任务-backup-tasks>3.6 备用任务(Backup Tasks)</h3><p>某一台机器执行慢，导致总时间超时</p><ul><li>硬盘出问题，导致读取慢</li><li>与其它 task 竞争 CPU、内存、本地磁盘、带宽</li><li>初始化代码有 bug，导致关闭缓存</li></ul><p>调优机制：当 MapReduce 操作接近完成时，master 调用 backup task 处理 in-progress task</p><h2 id=4-技巧-refinements>4 技巧(Refinements)</h2><h3 id=4-1-分区函数-partitioning-function>4.1 分区函数(Partitioning Function)</h3><ul><li>默认分区函数使用 hash(key) mod R</li><li>用户可自定义分区函数</li></ul><h3 id=4-2-顺序保证-ordering-guarantees>4.2 顺序保证(Ordering Guarantees)</h3><p>给定分区中，中间 key/value pair 按照 key 值增量顺序处理</p><h3 id=4-3-combiner-函数-combiner-function>4.3 Combiner 函数(Combiner Function)</h3><p>允许用户指定 combiner 函数，合并中间记录，减少重复数据的网络传输</p><h3 id=4-4-输入和输出的类型-input-and-output-types>4.4 输入和输出的类型(Input and Output Types)</h3><p>支持不同的数据输入/输出方式</p><ul><li>文本</li><li>数据库</li><li>内存中的数据结构</li><li>实现 Reader 接口支持新的输入类型</li></ul><h3 id=4-5-副作用-side-effects>4.5 副作用(Side-effects)</h3><p>某些情况增加辅助的输出文件，输出全部数据后，使用系统级的原子 rename 这些文件</p><h3 id=4-6-跳过损坏的记录-skipping-bad-records>4.6 跳过损坏的记录(Skipping Bad Records)</h3><p>用户程序 bug 导致系统 crash，worker 向 master 发送记录序号，多次发生后，master 可标记跳过这条记录</p><h3 id=4-7-本地执行-local-execution>4.7 本地执行(Local Execution)</h3><p>MapReduce 库的本地版本简化调试、profile、本地测试</p><h3 id=4-8-状态信息-status-information>4.8 状态信息(Status Information)</h3><p>master 内嵌 HTTP 服务显示状态信息，展示执行进度</p><h3 id=4-9-计数器-counters>4.9 计数器(Counters)</h3><ul><li>使用计数器统计不同事件发生的次数（已经处理了多少单次、已经索引了多少篇文档）</li><li>计数器周期性的从 worker 汇总到 master（附加在 ping 应答中）</li></ul><h2 id=5-性能-performance>5 性能(Performance)</h2><p>两个典型的例子</p><ul><li>对数据格式进行转换：对 1T 数据排序</li><li>从海量数据中抽取感兴趣的数据：1T 数据中进行模式匹配</li></ul><h3 id=5-1-集群配置-cluster-configuration>5.1 集群配置(Cluster Configuration)</h3><p>1800 台机器的集群</p><ul><li>2个2G主频、支持超线程的 Intel Xeon CPU</li><li>4G物理内存</li><li>2个160G的IDE硬盘</li><li>一个千兆网卡</li></ul><h3 id=5-2-grep-grep>5.2 Grep(Grep)</h3><ul><li>扫描10的10次方个由100字节组成的记录 1TB</li><li>输入拆分为64MB的块，M=15000</li><li>输出一个文件，R=1</li><li>耗时150秒，包括1分钟的启动时间，峰值速度30GB/s</li></ul><h3 id=5-3-排序-sort>5.3 排序(Sort)</h3><ul><li>处理10的10次方个由100字节组成的记录 1TB</li><li>排序结果输出到两路复制的 GFS 2TB</li><li>输入数据读取速度最快（本地读取）</li><li>排序速度比输出速度快（输出数据写了两份）</li></ul><h3 id=5-4-高效的备用任务-effect-of-backup-tasks>5.4 高效的备用任务(Effect of Backup Tasks)</h3><p>如果没有 backup task，需要多执行300秒，时间增加44%</p><h3 id=5-5-失效的机器-machine-failures>5.5 失效的机器(Machine Failures)</h3><p>kill 掉1746个进程中的200个，比正常执行多了5%</p><h2 id=6-经验-experience>6 经验(Experience)</h2><p>MapReduce 广泛应用于 Google</p><ul><li>大规模机器学习</li><li>Google news 和 Froogle</li><li>公共查询产品的报告中抽取数据</li><li>大量新应用和新产品中提取有用信息</li><li>大规模图形计算</li></ul><p>应用数：从 2003 年的 0 个增长到 2004 年 9 月 900 个</p><h3 id=6-1-大规模索引-large-scale-indexing>6.1 大规模索引(Large-Scale Indexing)</h3><p>最成功的应用：重写 Google 网络索引系统</p><p>处理20TB保存在 GFS 中的原始内容，经过5到10次 MapReduce 来建立索引</p><h2 id=7-相关工作-related-work>7 相关工作(Related Work)</h2><ul><li>并行计算的经典模型<a href=https://people.eecs.berkeley.edu/~driscoll/cs267/papers/scan_primitive.pdf>scan_primitive</a>、<a href=https://link.springer.com/chapter/10.1007%2FBFb0024729>SEP_scan</a>、<a href="https://dl.acm.org/citation.cfm?id=322232">PPC</a></li><li><a href=https://people.eecs.berkeley.edu/~driscoll/cs267/papers/BSP.pdf>BSP</a>、<a href=http://www.hds.bme.hu/~fhegedus/00%20-%20Numerics/B2015%20Using%20MPI%20-%20Portable%20Parallel%20Programming%20with%20the%20Message-Passing%20Interface.pdf>MPI</a>提供更高级别的并行处理抽象</li><li><a href=https://www.usenix.org/legacy/publications/library/proceedings/fast04/tech/full_papers/huston/huston_html/diamond-html.html>Diamond</a>、<a href=https://ieeexplore.ieee.org/document/928624>active disks</a>提供数据本地化策略的灵感</li><li><a href=https://www.sciencedirect.com/science/article/pii/S0167739X99000096>Charlotte System</a>提出 eager 调度机制，类似备用任务机制</li><li><a href=http://research.cs.wisc.edu/htcondor/doc/condor-practice.pdf>Condor</a>提供集群管理系统的理念</li><li><a href=https://people.eecs.berkeley.edu/~culler/papers/p243-arpaci-dusseau.pdf>Now-Sort</a>提供类似的排序机制</li><li><a href=http://now.cs.berkeley.edu/files/recent/river.pdf>River</a>提供一个编程模型，处理进程通过分布式队列传送数据的方式进行互相通讯</li><li><a href=http://pages.cs.wisc.edu/~remzi/Classes/736/Fall2003/Papers/badfs.pdf>BAD-FS</a>面向广域网，重新执行机制防止数据丢失、数据本地化调度</li><li><a href=https://people.eecs.berkeley.edu/~brewer/papers/TACC-sosp.pdf>TACC</a>用于简化构造高可用性网络服务的系统，重新执行机制实现容错</li></ul><h2 id=参考资料>参考资料</h2><ol><li><a href=https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/mapreduce-osdi04.pdf>MapReduce: Simplified Data Processing on Large Clusters</a></li><li><a href=http://blog.bizcloudsoft.com/wp-content/uploads/Google-MapReduce%E4%B8%AD%E6%96%87%E7%89%88_1.0.pdf>MapReduce中文版</a></li><li><a href=https://pdos.csail.mit.edu/6.824/labs/lab-1.html>6.824-lab-1</a></li></ol></div></div></section></main><footer class="footer is-dark"><div class=container><div class=has-text-centered><span class="is-size-5 is-size-6-mobile has-text-grey-light">&copy; 2019 baishen | Powered by <a href=https://gohugo.io/>Hugo</a></span></div></div></footer><script type=text/javascript>function navbarToggle(){const burger=document.querySelector('.navbar-burger');const menu=document.querySelector('.navbar-menu');burger.addEventListener('click',event=>{burger.classList.toggle("is-active");menu.classList.toggle("is-active");});}
(function(){navbarToggle();console.log("Welcome to baishen.me!");})();</script></body></html>